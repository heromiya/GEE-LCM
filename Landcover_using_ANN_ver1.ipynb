{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb2194a-de84-4631-bc4a-292b2ffbe89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pprint import pprint\n",
    "from google.cloud import storage\n",
    "\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = r'land-cover-mapping.json'\n",
    "\n",
    "storage_client = storage.Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bca8d24-aa79-4757-9ba8-bcc985c180a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ee\n",
    "ee.Authenticate()\n",
    "ee.Initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43dac9c1-bdf0-4db4-a48e-0e824eb321d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import shutil\n",
    "import time\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import folium\n",
    "\n",
    "from osgeo import gdal\n",
    "from osgeo import osr\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06bfbeed-5a39-4c07-ae4f-41c3d8e14d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the UserName and ref_point_name\n",
    "UserName = str(input(\"User Name: \"))\n",
    "ref_point_name = str(input('GEE Legacy Assets: '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8318bae-f5fc-4ccd-8f1a-ec4a5f984126",
   "metadata": {},
   "outputs": [],
   "source": [
    "cName = str(input('City Name: ')) \n",
    "lat_max = float(input('Maximum Latitute: ')) \n",
    "lat_min = float(input('Minimum Latitute: ')) \n",
    "lon_max = float(input('Maximum Longitude: '))\n",
    "lon_min = float(input('Minimum Longitude: '))  \n",
    "lyb = int(input('Begining Year of Landsat data: ')) # 1990\n",
    "lye = int(input('Ending Year of Landsat data: ')) # 1990\n",
    "ldb = int(input('Begining Day of Landsat data: ')) # 1\n",
    "lde = int(input('Ending Day of Landsat data: ')) # 366\n",
    "ep = int(input('Epoch: ')) # 25 100 200\n",
    "sr = int(input('Spatial Resolution: ')) # 120\n",
    "moas = int(input('Model output array of shape: ')) # 512, 128, 64\n",
    "lr = float(input('Model learning rate: ')) # 0.001, 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdac0fa4-9aaa-4245-baed-35b2cc8cbfce",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = time.time()\n",
    "timestamp = int(ts)\n",
    "\n",
    "blob_name = UserName + '_' + str(timestamp) + '/'\n",
    "\n",
    "project_name = 'land-cover-mapping-340607'\n",
    "bucket_name = 'landcovermapping'\n",
    "\n",
    "gcs_client = storage.Client(project=project_name)\n",
    "bucket = gcs_client.get_bucket(bucket_name)\n",
    "blob = bucket.blob(blob_name)\n",
    "blob.upload_from_string('', content_type='application/x-www-form-urlencoded;charset=UTF-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae2d0a1-3659-41a1-98bc-b7abc76570e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_class_value(feat):\n",
    "  return feat.set('class', ee.Number(feat.get('class')).subtract(1))\n",
    "\n",
    "\n",
    "def cloudMask(img):\n",
    "  return img.updateMask(img.select('BQA').lt(64))\n",
    "  \n",
    "\n",
    "def select_landsat(year):\n",
    "  if (year >= 2013):\n",
    "    return {\n",
    "        'bands': ['B2', 'B3', 'B4', 'B5', 'B6', 'B7'],\n",
    "        'FCCbands': ['B5', 'B4', 'B3'],\n",
    "        'TextureBand': ['B5'],\n",
    "        'bandsClassify': ['B2', 'B3', 'B4', 'B5', 'B6', 'B7','B5_1'],\n",
    "        'bandsGLCM': ['B2', 'B3', 'B4', 'B5', 'B6', 'B7', 'B5_asm', 'B5_contrast', \"B5_corr\", \"B5_var\", \"B5_idm\", \"B5_savg\", \"B5_svar\", \"B5_sent\", \"B5_ent\", \"B5_dvar\", \"B5_dent\", \"B5_imcorr1\", \"B5_imcorr2\",\"B5_maxcorr\", \"B5_diss\",  \"B5_inertia\", \"B5_shade\", \"B5_prom\"],\n",
    "        'Landsat': 'LANDSAT/LC08/C01/T1'\n",
    "    }\n",
    "\n",
    "  if (year >= 1999 and year <= 2002):\n",
    "    return {\n",
    "        'bands': ['B1', 'B2', 'B3', 'B4', 'B5', 'B7'],\n",
    "        'TextureBand': ['B4'],\n",
    "        'bandsClassify': ['B1', 'B2', 'B3', 'B4', 'B5', 'B7','B4_1'],\n",
    "        'bandsGLCM': ['B1', 'B2', 'B3', 'B4', 'B5', 'B7', 'B4_asm', 'B4_contrast',\"B4_corr\", \"B4_var\",\"B4_idm\",\"B4_savg\", \"B4_svar\",\"B4_sent\",\"B4_ent\",\"B4_dvar\",\"B4_dent\",\"B4_imcorr1\", \"B4_imcorr2\",\"B4_maxcorr\",\"B4_diss\",\"B4_inertia\",\"B4_shade\",\"B4_prom\"],\n",
    "        'FCCbands': ['B4', 'B3', 'B2'],\n",
    "        'Landsat': 'LANDSAT/LE07/C01/T1'\n",
    "    }\n",
    "\n",
    "  if (year >= 1984 and year <= 1998 or year >=2003 and year <=2012):\n",
    "    return{\n",
    "        'bands': ['B1', 'B2', 'B3', 'B4', 'B5', 'B7'],\n",
    "        'bandsClassify': ['B1', 'B2', 'B3', 'B4', 'B5', 'B7','B4_1'],\n",
    "        'bandsGLCM': ['B1', 'B2', 'B3', 'B4', 'B5', 'B7', 'B4_asm', 'B4_contrast',\"B4_corr\", \"B4_var\",\"B4_idm\",\"B4_savg\", \"B4_svar\",\"B4_sent\",\"B4_ent\",\"B4_dvar\",\"B4_dent\",\"B4_imcorr1\", \"B4_imcorr2\",\"B4_maxcorr\",\"B4_diss\",\"B4_inertia\",\"B4_shade\",\"B4_prom\"],\n",
    "        'FCCbands': ['B4', 'B3', 'B2'],\n",
    "        'TextureBand': ['B4'],\n",
    "        'Landsat': 'LANDSAT/LT05/C01/T1'\n",
    "    }\n",
    "  \n",
    "  if (year == 1983):\n",
    "    return{\n",
    "        'bands': ['B1', 'B2', 'B3', 'B4', 'B5', 'B7'],\n",
    "        'bandsClassify': ['B1', 'B2', 'B3', 'B4', 'B5', 'B7','B4_1'],\n",
    "        'bandsGLCM': ['B1', 'B2', 'B3', 'B4', 'B5', 'B7', 'B4_asm', 'B4_contrast',\"B4_corr\", \"B4_var\",\"B4_idm\",\"B4_savg\", \"B4_svar\",\"B4_sent\",\"B4_ent\",\"B4_dvar\",\"B4_dent\",\"B4_imcorr1\", \"B4_imcorr2\",\"B4_maxcorr\",\"B4_diss\",\"B4_inertia\",\"B4_shade\",\"B4_prom\"],\n",
    "        'FCCbands': ['B4', 'B3', 'B2'],\n",
    "        'TextureBand': ['B4'],\n",
    "        'Landsat': 'LANDSAT/LT04/C01/T1'\n",
    "    }\n",
    "  \n",
    "  if (year >= 1979 and year <= 1982):\n",
    "    return {\n",
    "        'bands': ['B4_median', 'B5_median', 'B6_median','B7_median','B6_median_1'],\n",
    "        'bandsClassify': ['B4_median', 'B5_median', 'B6_median', 'B7_median'],\n",
    "        'FCCbands': ['B6_median', 'B5_median', 'B4_median'],\n",
    "        'TextureBand': ['B6_median'],\n",
    "        'Landsat': 'LANDSAT/LM03/C01/T1'\n",
    "    }\n",
    "\n",
    "  if (year >= 1975 and year <= 1978):\n",
    "    return {\n",
    "        'bands': ['B4_median', 'B5_median', 'B6_median','B7_median','B6_median_1'],\n",
    "        'bandsClassify': ['B4_median', 'B5_median', 'B6_median', 'B7_median'],\n",
    "        'FCCbands': ['B6_median', 'B5_median', 'B4_median'],\n",
    "        'TextureBand': ['B6_median'],\n",
    "        'Landsat': 'LANDSAT/LM02/C01/T2'\n",
    "    }\n",
    "\n",
    "  if (year >= 1972 and year <= 1974):\n",
    "    return {\n",
    "        'bands': ['B4_median', 'B5_median', 'B6_median','B7_median','B6_median_1'],\n",
    "        'bandsClassify': ['B4_median', 'B5_median', 'B6_median', 'B7_median'],\n",
    "        'FCCbands': ['B6_median', 'B5_median', 'B4_median'],\n",
    "        'TextureBand': ['B6_median'],\n",
    "        'Landsat': 'LANDSAT/LM01/C01/T2'\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b1f4975-6b1f-461b-a7d7-5b345560a143",
   "metadata": {},
   "outputs": [],
   "source": [
    "def landsat_product(landsat_id):\n",
    "  if(landsat_id == 'LANDSAT/LM01/C01/T2' or landsat_id == 'LANDSAT/LM02/C01/T2' or landsat_id == 'LANDSAT/LM03/C01/T1'):\n",
    "    image = ee.ImageCollection(landsat_id).filterDate(str(gtYearBegin) + '-01-01',str(gtYearEnd) + '-12-31').filter(ROI[roi]['doyFilterLandsat']).filterBounds(out_ext).filterMetadata('CLOUD_COVER_LAND', 'less_than', 20).map(cloudMask).reduce(ee.Reducer.median())\n",
    "    return {\n",
    "      'region': image.geometry().bounds().getInfo(),\n",
    "      'image': image,\n",
    "      'image_int': image.toByte()       \n",
    "    }\n",
    "  else:\n",
    "    image_col = ee.ImageCollection(landsat_id).filterDate(str(gtYearBegin) + '-01-01',str(gtYearEnd) + '-12-31').filter(ROI[roi]['doyFilterLandsat']).filterBounds(out_ext)\n",
    "    return {\n",
    "      'region': image_col.geometry().bounds().getInfo(),\n",
    "      'image': ee.Algorithms.Landsat.simpleComposite(image_col, 50, cloud, 40, True),\n",
    "      'image_int': ee.Algorithms.Landsat.simpleComposite(image_col, 50, cloud, 40, False)\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec834227-8689-43c5-b2cf-48357528c462",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_indices(params, product):\n",
    "  \n",
    "  if(params['Landsat']=='LANDSAT/LC08/C01/T1'):\n",
    "    swir  = product['image'].select('B6')\n",
    "    nir   = product['image'].select('B5')\n",
    "    red   = product['image'].select('B4')\n",
    "    green = product['image'].select('B3')\n",
    "\n",
    "    ndvi  = nir.subtract(red).divide(nir.add(red))\n",
    "    ndbi  = swir.subtract(nir).divide(swir.add(nir))\n",
    "    bi    = ndbi.subtract(ndvi)\n",
    "    ndwi  = green.subtract(swir).divide(green.add(swir))\n",
    "\n",
    "    product['image'] = product['image'].addBands([ndvi, ndbi, bi, ndwi])\n",
    "    product['image'] = product['image'].rename('B1','B2','B3','B4','B5','B6','B7','B8','B9','B10','B11','ndvi','ndbi','bi','ndwi')\n",
    "\n",
    "    params['bandsClassify'].extend(['ndvi', 'ndbi', 'bi', 'ndwi'])\n",
    "\n",
    "\n",
    "  if(params['Landsat'] == 'LANDSAT/LE07/C01/T1'):\n",
    "    swir  = product['image'].select('B5')\n",
    "    nir   = product['image'].select('B4')\n",
    "    red   = product['image'].select('B3')\n",
    "    green = product['image'].select('B2')\n",
    "\n",
    "    ndvi  = nir.subtract(red).divide(nir.add(red))\n",
    "    ndbi  = swir.subtract(nir).divide(swir.add(nir))\n",
    "    bi    = ndbi.subtract(ndvi)\n",
    "    ndwi  = green.subtract(swir).divide(green.add(swir))\n",
    "\n",
    "    product['image'] = product['image'].addBands([ndvi, ndbi, bi, ndwi])\n",
    "    product['image'] = product['image'].rename('B1','B2','B3','B4','B5','B6_VCID_1','B6_VCID_2','B7','B8','ndvi','ndbi','bi','ndwi')\n",
    "\n",
    "    params['bandsClassify'].extend(['ndvi', 'ndbi', 'bi', 'ndwi'])\n",
    "    \n",
    "\n",
    "  if(params['Landsat'] == 'LANDSAT/LM04/C01/T1' or params['Landsat'] == 'LANDSAT/LT05/C01/T1'):\n",
    "    swir  = product['image'].select('B5')\n",
    "    nir   = product['image'].select('B4')\n",
    "    red   = product['image'].select('B3')\n",
    "    green = product['image'].select('B2')\n",
    "\n",
    "    ndvi  = nir.subtract(red).divide(nir.add(red))\n",
    "    ndbi  = swir.subtract(nir).divide(swir.add(nir))\n",
    "    bi    = ndbi.subtract(ndvi)\n",
    "    ndwi  = green.subtract(swir).divide(green.add(swir))\n",
    "\n",
    "    product['image'] = product['image'].addBands([ndvi, ndbi, bi, ndwi])\n",
    "    product['image'] = product['image'].rename('B1','B2','B3','B4','B5','B6','B7','ndvi','ndbi','bi','ndwi')\n",
    "\n",
    "    params['bandsClassify'].extend(['ndvi', 'ndbi', 'bi', 'ndwi'])\n",
    "\n",
    "\n",
    "  if(params['Landsat'] == 'LANDSAT/LM01/C01/T2' or params['Landsat'] == 'LANDSAT/LM02/C01/T2' or params['Landsat'] == 'LANDSAT/LM03/C01/T1'):\n",
    "    swir = product['image'].select('B6_median')\n",
    "    nir = product['image'].select('B6_median')\n",
    "    red = product['image'].select('B5_median')\n",
    "\n",
    "    ndvi = nir.subtract(red).divide(nir.add(red))\n",
    "\n",
    "    product['image'] = product['image'].addBands(ndvi)\n",
    "    product['image'] = product['image'].rename('B4_median','B5_median','B6_median','B7_median','BQA_median','ndvi')\n",
    "\n",
    "    params['bandsClassify'].append('ndvi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d6606c0-1a9c-4bdb-a7cf-b33e054833df",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROI = [\n",
    "       {'cityName': cName, 'LatMax': lat_max, 'LatMin': lat_min, 'LonMax': lon_max, 'LonMin': lon_min, 'yearBegin':lyb, 'yearEnd':lye, 'doyFilter':ee.Filter.And(ee.Filter.greaterThanOrEquals('doy',  ldb), ee.Filter.lessThanOrEquals('doy',  lde)), 'doyFilterLandsat': ee.Filter.dayOfYear(ldb,lde)},\n",
    "        # {'cityName': 'Ethiopia', 'LatMax': 14.911944087898716, 'LatMin': 11.9, 'LonMax': 39.102228429963795, 'LonMin': 36.663263586213795, 'yearBegin':1990, 'yearEnd':1990, 'doyFilter':ee.Filter.And(ee.Filter.greaterThanOrEquals('doy',  1), ee.Filter.lessThanOrEquals('doy',  366)), 'doyFilterLandsat': ee.Filter.dayOfYear(1,366)},\n",
    "      #  {'cityName': 'Laguna Lake-Wet', 'LatMax': 14.5758304600000006, 'LatMin': 13.9641799899999999, 'LonMax': 121.6324386600000054, 'LonMin': 121.0053329499999961, 'yearBegin':1976, 'yearEnd':1976, 'doyFilter':ee.Filter.And(ee.Filter.greaterThanOrEquals('doy',  153), ee.Filter.lessThanOrEquals('doy',  305)), 'doyFilterLandsat': ee.Filter.dayOfYear(153, 305)},\n",
    "      #  {'cityName': 'Laguna Lake-Dry', 'LatMax': 14.5758304600000006, 'LatMin': 13.9641799899999999, 'LonMax': 121.6324386600000054, 'LonMin': 121.0053329499999961, 'yearBegin':1976, 'yearEnd':1976, 'doyFilter':ee.Filter.Or(ee.Filter.greaterThanOrEquals('doy',  306), ee.Filter.lessThanOrEquals('doy',  152)), 'doyFilterLandsat': ee.Filter.Or(ee.Filter.dayOfYear(1, 152),ee.Filter.dayOfYear(306, 366))}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0362a2c-2f44-4066-bbf4-725323fcf9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "roi= ''\n",
    "kernel = ee.Kernel.gaussian(1)\n",
    "\n",
    "out_ext = ''\n",
    "\n",
    "cloud = 30\n",
    "spatial_resolution = sr\n",
    "n_sample = 10000\n",
    "distance = 370000\n",
    "\n",
    "base_distance = 5000\n",
    "patch_size = 256\n",
    "buffer_distance = base_distance * (round((spatial_resolution * 0.5 * patch_size)/base_distance) +1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9070beb9-fa26-4078-aeaf-7882e8a082c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_point = ee.FeatureCollection(ref_point_name)\n",
    "ref_point = ref_point.map(reduce_class_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f3f44d-17c9-4c52-98f8-f4f817b56357",
   "metadata": {},
   "outputs": [],
   "source": [
    "for roi in range(0, len(ROI), 1):\n",
    "  city_name = ROI[roi]['cityName']\n",
    "  year_begin = ROI[roi]['yearBegin']\n",
    "  year_end = ROI[roi]['yearEnd']\n",
    "\n",
    "  USER_NAME = UserName\n",
    "  IMAGE_FILE_PREFIX = city_name + '_' + str(year_begin) + '_' + str(year_end) + '_' + str(timestamp)\n",
    "  FOLDER_NAME = USER_NAME + '_' + IMAGE_FILE_PREFIX + '_' + str(timestamp)\n",
    "\n",
    "  for year in range(year_begin, year_end+1, 1):\n",
    "    nSampleClass = []\n",
    "    out_ext = ee.Geometry.Rectangle([ ROI[roi]['LonMin'], ROI[roi]['LatMin'], ROI[roi]['LonMax'], ROI[roi]['LatMax']])\n",
    "    out_ext_center = out_ext.centroid()\n",
    "\n",
    "    out_ext_buffer = out_ext.buffer(buffer_distance).bounds()\n",
    "\n",
    "    center_lat = out_ext_center.getInfo()['coordinates'][1]\n",
    "    center_lon = out_ext_center.getInfo()['coordinates'][0]\n",
    "\n",
    "    landsat_params = select_landsat(year_begin)\n",
    "\n",
    "    gtYearBegin = year_begin\n",
    "    gtYearEnd = year_end\n",
    "\n",
    "\n",
    "    product = landsat_product(landsat_params['Landsat'])\n",
    "    \n",
    "    LABEL_DATA = ref_point.filter(ee.Filter.And(ee.Filter.greaterThanOrEquals('year', gtYearBegin), ee.Filter.lessThanOrEquals('year', gtYearEnd), ROI[roi]['doyFilter']))\n",
    "    LABEL_DATA = LABEL_DATA.filterBounds(product['region'])\n",
    "\n",
    "    add_indices(landsat_params, product)\n",
    "\n",
    "    gt_image = product['image']\n",
    "    gt_image_int = product['image_int']\n",
    "    gt_image_texture = gt_image.addBands(gt_image_int.select(landsat_params['TextureBand']).entropy(kernel))\n",
    "\n",
    "    out_image = product['image'].clip(out_ext_buffer)\n",
    "    out_image_int = product['image_int'].clip(out_ext_buffer)\n",
    "    out_image_texture = out_image.addBands(out_image_int.select(landsat_params['TextureBand']).entropy(kernel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3164b9f9-f0a1-4a52-b9a4-801ff8c4cea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa407cc-7aed-46c6-80e9-daa13cd27893",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapid = out_image_texture.getMapId({'bands': [landsat_params['FCCbands'][0], landsat_params['FCCbands'][1], landsat_params['FCCbands'][2]], 'min': 0, 'max': 255})\n",
    "map = folium.Map(location=[center_lat, center_lon]) \n",
    "folium.TileLayer(\n",
    "    tiles=mapid['tile_fetcher'].url_format,\n",
    "    attr='Map Data &copy; <a href=\"https://earthengine.google.com/\">Google Earth Engine</a>',\n",
    "    overlay=True,\n",
    "    name='Out Image Texture',\n",
    "  ).add_to(map)\n",
    "map.add_child(folium.LayerControl())\n",
    "map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "955e6c05-7a63-4ca0-92a4-7c5a1a7d9ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "BANDS = landsat_params['bandsClassify']\n",
    "LABEL = 'class'\n",
    "N_CLASSES = 4\n",
    "\n",
    "FEATURE_NAMES = list(BANDS)\n",
    "FEATURE_NAMES.append(LABEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922921ad-19ef-45d1-a8e1-c858418574a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Bucket_Blob_Name = bucket_name + '/' + UserName + '_' + str(timestamp)\n",
    "\n",
    "MY_BUCKET_PATH = os.getcwd()\n",
    "FOLDER_PATH = MY_BUCKET_PATH + '/' + FOLDER_NAME\n",
    "SHARED_DRIVE_PATH = '/content/drive/Shareddrives/MiyazakiLab/LC_mapping_models/'\n",
    "\n",
    "TRAIN_FILE_PREFIX = 'Training_' + str(timestamp)\n",
    "TEST_FILE_PREFIX = 'Testing_' + str(timestamp)\n",
    "\n",
    "file_extension = '.tfrecord.gz'\n",
    "TRAIN_FILE_PATH =  MY_BUCKET_PATH + '/' + FOLDER_NAME + '/' + 'sample/' + TRAIN_FILE_PREFIX + file_extension\n",
    "TEST_FILE_PATH = MY_BUCKET_PATH + '/' + FOLDER_NAME + '/' + 'sample/' + TEST_FILE_PREFIX + file_extension\n",
    "\n",
    "OUTPUT_IMAGE_TFR = MY_BUCKET_PATH + '/' + FOLDER_NAME + '/' + IMAGE_FILE_PREFIX+'.TFRecord'\n",
    "OUTPUT_IMAGE_TIF = MY_BUCKET_PATH + '/' + FOLDER_NAME + '/' + IMAGE_FILE_PREFIX+'.tif'\n",
    "\n",
    "EXPORT_REGION = out_ext\n",
    "OUTPUT_ASSET_ID = 'users/' + USER_NAME + '/demo'\n",
    "\n",
    "TRAIN_FILE_BUCKET = TRAIN_FILE_PREFIX + file_extension\n",
    "TEST_FILE_BUCKET = TEST_FILE_PREFIX + file_extension\n",
    "\n",
    "path = os.path.join(os.getcwd(), FOLDER_NAME)\n",
    "os.mkdir(path)\n",
    "# os.makedirs(dest_dir, exist_ok = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37ddcb3-9dda-4202-9dec-c1cf3b609715",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = gt_image_texture.sampleRegions(\n",
    "    collection = LABEL_DATA,\n",
    "    properties = [LABEL],\n",
    "    scale = spatial_resolution,\n",
    ").randomColumn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "539b5673-2b03-4094-ae5f-b11c805e89bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "training = sample.filter(ee.Filter.lt('random', 0.8))\n",
    "testing = sample.filter(ee.Filter.gte('random', 0.8))\n",
    "\n",
    "pprint({'training': training.first().getInfo()})\n",
    "pprint({'testing': testing.first().getInfo()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3def6e3a-93bb-4f4f-9b80-7e4b68c6073b",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_task = ee.batch.Export.table.toCloudStorage(\n",
    "  collection=training,\n",
    "  description='Training Export',\n",
    "  bucket=bucket_name,\n",
    "  fileNamePrefix=TRAIN_FILE_PREFIX,\n",
    "  fileFormat='TFRecord',\n",
    "  selectors=FEATURE_NAMES)\n",
    "testing_task = ee.batch.Export.table.toCloudStorage(\n",
    "  collection=testing,\n",
    "  description='Testing Export',\n",
    "  bucket=bucket_name,\n",
    "  fileNamePrefix=TEST_FILE_PREFIX,\n",
    "  fileFormat='TFRecord',\n",
    "  selectors=FEATURE_NAMES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddeedc34-0ec9-4bab-8885-18587808b63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_task.start()\n",
    "testing_task.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb4dd680-0eb5-40bf-b2ab-d56dfc973be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "while training_task.active():\n",
    "  print('Polling for task (id: {}).'.format(training_task.id))\n",
    "  time.sleep(20)\n",
    "print('Done with training export.')\n",
    "\n",
    "while testing_task.active():\n",
    "  print('Polling for task (id: {}).'.format(testing_task.id))\n",
    "  time.sleep(20)\n",
    "print('Done with testing export.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95332b27-8202-4bc4-8989-9f4366e389d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_blob(bucket_name, blob_name, destination_bucket_name, destination_blob_name):\n",
    "\n",
    "    storage_client = storage.Client()\n",
    "\n",
    "    source_bucket = storage_client.bucket(bucket_name)\n",
    "    source_blob = source_bucket.blob(blob_name)\n",
    "    destination_bucket = storage_client.bucket(destination_bucket_name)\n",
    "\n",
    "    blob_copy = source_bucket.copy_blob(source_blob, destination_bucket, destination_blob_name)\n",
    "    source_bucket.delete_blob(blob_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11ca077-4ff8-4153-ba29-887776abbfe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "move_blob(bucket_name, TRAIN_FILE_BUCKET, bucket_name, blob_name + TRAIN_FILE_BUCKET)\n",
    "move_blob(bucket_name, TEST_FILE_BUCKET, bucket_name, blob_name + TEST_FILE_BUCKET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58180b1d-c088-48c5-b6d5-8f1d68bbdc7e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def download_file_from_bucket(blog_name, file_path, bucket_name):\n",
    "    try:\n",
    "        bucket = storage_client.get_bucket(bucket_name)\n",
    "        blob = bucket.blob(blog_name)\n",
    "        with open(file_path, 'wb') as f:\n",
    "            storage_client.download_blob_to_file(blob, f)\n",
    "        print('Saved')\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55101bb0-3837-45e2-b1d8-0b2f0a3b160e",
   "metadata": {},
   "outputs": [],
   "source": [
    "download_file_from_bucket(blob_name + TRAIN_FILE_BUCKET, os.path.join(os.getcwd(), FOLDER_NAME + '/'+ TRAIN_FILE_BUCKET), bucket_name)\n",
    "download_file_from_bucket(blob_name + TEST_FILE_BUCKET, os.path.join(os.getcwd(), FOLDER_NAME + '/' + TEST_FILE_BUCKET), bucket_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a077c8df-d0af-4b0c-b9a6-1b3a86a0eecc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "src_dir = MY_BUCKET_PATH + '/' + FOLDER_NAME\n",
    "src_files = os.listdir(src_dir)\n",
    "\n",
    "dest_dir = os.path.join(src_dir, 'sample')\n",
    "\n",
    "os.makedirs(dest_dir, exist_ok = True)\n",
    "\n",
    "for file in src_files:\n",
    "    shutil.move(os.path.join(src_dir, file), dest_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9208d0b-3665-4edf-8ae4-1c1a69df5fca",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EsS6YBcjnSJ7",
    "outputId": "2c90f8af-c85c-486c-c2d8-61a1b435cb6c"
   },
   "outputs": [],
   "source": [
    "print('Found training file.' if tf.io.gfile.exists(TRAIN_FILE_PATH) \n",
    "    else 'No training file found.')\n",
    "\n",
    "print('Found testing file.' if tf.io.gfile.exists(TEST_FILE_PATH) \n",
    "    else 'No testing file found.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1b15fa-3394-4bb3-9ff5-eae5f6efc2a5",
   "metadata": {
    "id": "AN-cQlaS0yEP"
   },
   "outputs": [],
   "source": [
    "train_dataset = tf.data.TFRecordDataset(TRAIN_FILE_PATH, compression_type='GZIP')\n",
    "test_dataset = tf.data.TFRecordDataset(TEST_FILE_PATH, compression_type='GZIP')\n",
    "\n",
    "# print(iter(train_dataset).next())\n",
    "# print(iter(test_dataset).next())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb37dbc-db63-486d-8959-dd31917ade99",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [tf.io.FixedLenFeature(shape=[1], dtype=tf.float32) for k in FEATURE_NAMES]\n",
    "\n",
    "features_dict = dict(zip(FEATURE_NAMES, columns))\n",
    "\n",
    "pprint(features_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449009ef-4bb2-4ed6-89f2-ac0c150a7d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_tfrecord(example_proto):\n",
    "  parsed_features = tf.io.parse_single_example(example_proto, features_dict)\n",
    "  labels = parsed_features.pop(LABEL)\n",
    "  return parsed_features, tf.cast(labels, tf.int32)\n",
    "\n",
    "parsed_trainset = train_dataset.map(parse_tfrecord, num_parallel_calls=5)\n",
    "parsed_testset = test_dataset.map(parse_tfrecord, num_parallel_calls=5)\n",
    "\n",
    "# pprint(iter(parsed_trainset))\n",
    "# pprint(iter(parsed_testset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79cc79bd-ded0-407b-9299-7f8c0267dcf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "\n",
    "def to_tuple(inputs, label):\n",
    "  return (tf.transpose(list(inputs.values())), tf.one_hot(indices=label, depth=N_CLASSES))\n",
    "\n",
    "input_dataset = parsed_trainset.map(to_tuple).batch(batch_size)\n",
    "validate_dataset = parsed_testset.map(to_tuple).batch(batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62dccb4-e64f-44f5-af5e-396a4e77937e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = tf.keras.models.Sequential([\n",
    "#   tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "#   tf.keras.layers.Dropout(0.1),\n",
    "#   tf.keras.layers.Dense(64, activation=tf.nn.relu),\n",
    "#   tf.keras.layers.Dropout(0.1),\n",
    "#   tf.keras.layers.Dense(64, activation=tf.nn.relu),\n",
    "#   tf.keras.layers.Dropout(0.1),\n",
    "#   tf.keras.layers.Dense(64, activation=tf.nn.relu),\n",
    "#   tf.keras.layers.Dense(64, activation=tf.nn.relu),\n",
    "#   tf.keras.layers.Dense(N_CLASSES, activation=tf.nn.softmax)\n",
    "# ])\n",
    "\n",
    "#NEW NN STRUCTURE\n",
    "\n",
    "drop = 0.05\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Dense(moas, activation=tf.nn.relu),\n",
    "  tf.keras.layers.Dropout(drop),\n",
    "  tf.keras.layers.Dense(moas, activation=tf.nn.relu),\n",
    "  tf.keras.layers.Dropout(drop),\n",
    "  tf.keras.layers.Dense(moas, activation=tf.nn.relu),\n",
    "  tf.keras.layers.Dropout(drop),\n",
    "  tf.keras.layers.Dense(moas, activation=tf.nn.relu),\n",
    "  tf.keras.layers.Dropout(drop),\n",
    "  tf.keras.layers.Dense(moas, activation=tf.nn.relu),\n",
    "  tf.keras.layers.Dropout(drop),\n",
    "  tf.keras.layers.Dense(moas, activation=tf.nn.relu),\n",
    "  tf.keras.layers.Dropout(drop),\n",
    "  tf.keras.layers.Dense(moas, activation=tf.nn.relu),\n",
    "  tf.keras.layers.Dropout(drop),\n",
    "  tf.keras.layers.Dense(moas, activation=tf.nn.relu),\n",
    "  tf.keras.layers.Dropout(drop),\n",
    "  tf.keras.layers.Dense(moas, activation=tf.nn.relu),\n",
    "  tf.keras.layers.Dense(N_CLASSES, activation=tf.nn.softmax)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f93ae4-c29e-4f36-8c01-08c578246876",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer= tf.keras.optimizers.Adam(\n",
    "    learning_rate=lr),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy', 'mse'],\n",
    "    # run_eagerly=True         \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda6ab23-2fbf-4285-992e-79ce69aab2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "\n",
    "log_d = MY_BUCKET_PATH + '/' + FOLDER_NAME + '/' + 'model'\n",
    "os.makedirs(log_d, exist_ok=True)\n",
    "print(log_d)\n",
    "def build_callbacks():\n",
    "    checkpointer = ModelCheckpoint(filepath = log_d, verbose=0, save_best_only=True, monitor='val_loss')\n",
    "    callbacks = [checkpointer]\n",
    "    return callbacks\n",
    "history = model.fit(x=input_dataset,validation_data=(validate_dataset), epochs=ep, callbacks=build_callbacks())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a783e38-87a4-4b9b-a001-6e501b44c356",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8abfe4af-1e12-4ac2-b905-6228772901d6",
   "metadata": {},
   "outputs": [],
   "source": [
    " model.evaluate(validate_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218d6957-6620-4696-b84a-b6e1f480d9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_export_options = {\n",
    "    'patchDimensions': [patch_size, patch_size],\n",
    "    'maxFileSize': 104857600,\n",
    "    'compressed': True\n",
    "}\n",
    "\n",
    "image_task = ee.batch.Export.image.toCloudStorage(\n",
    "  image=out_image_texture,\n",
    "  description='Image Export',\n",
    "  fileNamePrefix= IMAGE_FILE_PREFIX,\n",
    "  bucket=bucket_name,\n",
    "  scale=spatial_resolution,\n",
    "  fileFormat='TFRecord',\n",
    "  region=out_ext_buffer,\n",
    "  formatOptions=image_export_options,\n",
    ")\n",
    "\n",
    "image_task.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d990cfa-8ecc-4bf3-a51f-fd9993fe0188",
   "metadata": {},
   "outputs": [],
   "source": [
    "while image_task.active():\n",
    "  print('Polling for task (id: {}).'.format(image_task.id))\n",
    "  time.sleep(20)\n",
    "print('Done with image export.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ece945-3e97-4d31-910c-f42f43380405",
   "metadata": {},
   "outputs": [],
   "source": [
    "blobs = storage_client.list_blobs(bucket_name)\n",
    "\n",
    "names= []\n",
    "\n",
    "x = int(len(IMAGE_FILE_PREFIX))\n",
    "\n",
    "for blob in blobs:\n",
    "    if len(blob.name) > x:\n",
    "        if blob.name[:x] == IMAGE_FILE_PREFIX:\n",
    "            # print(blob.name)\n",
    "            download_file_from_bucket(blob.name, FOLDER_PATH + '/'+ blob.name, bucket_name)\n",
    "            move_blob(bucket_name, blob.name, bucket_name, blob_name + blob.name)\n",
    "            # print(blob.name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f8c5f0-3c3d-41d1-a118-eb72e50f06fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfrecord_list = glob.glob(MY_BUCKET_PATH +'/' + FOLDER_NAME + '/' + '*.tfrecord.gz')\n",
    "tfrecord_list.sort()\n",
    "pprint(tfrecord_list)\n",
    "\n",
    "json_list = glob.glob(MY_BUCKET_PATH +'/' + FOLDER_NAME + '/' + '*.json')\n",
    "pprint(json_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "446fcf26-d985-4172-9e9a-bba43b2d49a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(json_list[0], \"r\") as read_file:\n",
    "   mixer = json.load(read_file)\n",
    "\n",
    "mixer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb600f0-9e72-49ac-ba0e-80f3a02562d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_width = mixer['patchDimensions'][0]\n",
    "patch_height = mixer['patchDimensions'][1]\n",
    "patches = mixer['totalPatches']\n",
    "patch_dimensions_flat = [patch_width*patch_height, 1]\n",
    "\n",
    "image_columns = [\n",
    "                tf.io.FixedLenFeature(shape=patch_dimensions_flat, dtype=tf.float32) for k in BANDS\n",
    "]\n",
    "\n",
    "image_features_dict = dict(zip(BANDS, image_columns))\n",
    "\n",
    "image_dataset = tf.data.TFRecordDataset(tfrecord_list, compression_type='GZIP')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88f4d3d-bce5-4120-89ce-f3b43a53ef3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_image(example_proto):\n",
    "  return tf.io.parse_single_example(example_proto, image_features_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11703211-42fe-4d26-9a91-5ef46cfc42ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dataset = image_dataset.map(parse_image, num_parallel_calls=5)\n",
    "\n",
    "image_dataset = image_dataset.flat_map(\n",
    "    lambda features: tf.data.Dataset.from_tensor_slices(features)\n",
    ")\n",
    "\n",
    "image_dataset = image_dataset.map(\n",
    "  lambda data_dict: (tf.transpose(list(data_dict.values())), )\n",
    ")\n",
    "\n",
    "image_dataset = image_dataset.batch(patch_width * patch_height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f662bd12-d6e5-47c0-9a96-586fcd866c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(image_dataset, steps=patches, verbose=1)\n",
    "print(predictions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf3ed12-962b-4abf-8c70-8c2eaced96b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = tf.io.TFRecordWriter(OUTPUT_IMAGE_TFR)\n",
    "\n",
    "patch = [[]]\n",
    "cur_patch = 1\n",
    "for prediction in predictions:\n",
    "  patch[0].append(tf.argmax(prediction, 1))\n",
    "\n",
    "  if (len(patch[0])==patch_width*patch_height):\n",
    "    print('Done with Patch ' + str(cur_patch) + ' of ' + str(patches) + '...')\n",
    "    example = tf.train.Example(\n",
    "        features=tf.train.Features(\n",
    "            feature={\n",
    "                'prediction': tf.train.Feature(\n",
    "                    float_list=tf.train.FloatList(\n",
    "                        value=patch[0]\n",
    "                    )\n",
    "                )\n",
    "            }\n",
    "        )\n",
    "    )\n",
    "\n",
    "    writer.write(example.SerializeToString())\n",
    "    patch=[[]]\n",
    "    cur_patch +=1\n",
    "  \n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b885fa6-e4e3-4e90-b310-08aae70e3408",
   "metadata": {},
   "outputs": [],
   "source": [
    "record_iterator = tf.compat.v1.python_io.tf_record_iterator(path=OUTPUT_IMAGE_TFR)\n",
    "\n",
    "n_row = patches/mixer['patchesPerRow']\n",
    "n_col = mixer['patchesPerRow']\n",
    "current_row = 0\n",
    "current_col = 0\n",
    "counter = 0\n",
    "\n",
    "for string_record in record_iterator:\n",
    "  example = tf.train.Example()\n",
    "  example.ParseFromString(string_record)\n",
    "  values = np.array(example.features.feature['prediction'].float_list.value).reshape(patch_width, patch_height).astype(np.int8)\n",
    "\n",
    "  if (current_col==0):\n",
    "    horizontal_strip = values\n",
    "  else:\n",
    "    horizontal_strip = np.concatenate([horizontal_strip, values], axis=1)\n",
    "  current_col += 1\n",
    "\n",
    "  if (current_col == n_col):\n",
    "    if (current_row==0):\n",
    "      image = horizontal_strip\n",
    "    else:\n",
    "      image = np.concatenate([image, horizontal_strip], axis=0)\n",
    "      horizontal_strip = []\n",
    "\n",
    "    current_row +=1\n",
    "    current_col = 0\n",
    "    print(counter)\n",
    "  counter +=1\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ae4867-7a2d-4746-a640-c6d91b183202",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgplot = plt.imshow(image, cmap=plt.get_cmap('jet'), vmin=0, vmax=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e9ae5e-c7a5-447e-aee0-32f85ddd185a",
   "metadata": {},
   "outputs": [],
   "source": [
    "affine = mixer['projection']['affine']['doubleMatrix']\n",
    "geotransform = (affine[2], affine[0], affine[1], affine[5], affine[3], affine[4])\n",
    "crs = int(mixer['projection']['crs'][-4:])\n",
    "print(affine)\n",
    "print(geotransform)\n",
    "print(crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f084a7-94af-41f3-8835-0bd7bc201e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "ny, nx = image.shape\n",
    "dst_ds = gdal.GetDriverByName('GTiff').Create(OUTPUT_IMAGE_TIF, nx, ny, 1, gdal.GDT_Byte)\n",
    "dst_ds.SetGeoTransform(tuple(geotransform))\n",
    "srs = osr.SpatialReference()\n",
    "srs.ImportFromEPSG(crs)\n",
    "dst_ds.SetProjection(srs.ExportToWkt())\n",
    "dst_ds.GetRasterBand(1).WriteArray(image)\n",
    "dst_ds.FlushCache()\n",
    "dst_ds = None\n",
    "\n",
    "print(\"Exorting \" + OUTPUT_IMAGE_TIF + \" completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4265dd1e-da8a-4c70-9e61-d60cd8728af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fcc_image = out_image.select(landsat_params['FCCbands'])\n",
    "fcc_prefix = city_name + '_' + str(year_begin) + '_' + str(year_end)+'_fcc'\n",
    "fcc_task = ee.batch.Export.image.toCloudStorage(**{\n",
    "    'image': fcc_image,\n",
    "    'description': fcc_prefix,\n",
    "    'bucket': bucket_name,\n",
    "    'fileNamePrefix': fcc_prefix,\n",
    "    'scale': spatial_resolution,\n",
    "    'region': out_ext\n",
    "})\n",
    "\n",
    "fcc_task.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390312bc-f1e3-4f35-a5b5-0d3cf54795a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "while fcc_task.active():\n",
    "  print('Polling for task (id: {}).'.format(fcc_task.id))\n",
    "  time.sleep(20)\n",
    "print('Done with fcc image export.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42aba9ce-2782-4e00-986a-ff00db11142a",
   "metadata": {},
   "outputs": [],
   "source": [
    "download_file_from_bucket(fcc_prefix + '.tif', FOLDER_PATH + '/'+ fcc_prefix + '.tif', bucket_name)\n",
    "move_blob(bucket_name, fcc_prefix + '.tif' , bucket_name, blob_name + fcc_prefix + '.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d47462d-a6fb-46ed-aad3-2cdf34d1aa7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lc_dir = MY_BUCKET_PATH + '/' + FOLDER_NAME + '/' + 'lc_map'\n",
    "fcc_path = MY_BUCKET_PATH + '/' + FOLDER_NAME + '/' + fcc_prefix+'.tif'\n",
    "ref_dir = MY_BUCKET_PATH + '/' + FOLDER_NAME + '/' + 'ref_map'\n",
    "\n",
    "os.makedirs(lc_dir, exist_ok = True)\n",
    "os.makedirs(ref_dir, exist_ok = True)\n",
    "\n",
    "print(lc_dir)\n",
    "# print(path)\n",
    "\n",
    "\n",
    "for name in os.listdir(path):\n",
    "    if name[:x] == IMAGE_FILE_PREFIX:\n",
    "        # print (name[-12:])\n",
    "        if name[-12:] == file_extension:\n",
    "            print(name)\n",
    "            shutil.move(os.path.join(path, name), lc_dir)\n",
    "shutil.move(OUTPUT_IMAGE_TFR, lc_dir)    \n",
    "shutil.move(OUTPUT_IMAGE_TIF, lc_dir)\n",
    "shutil.move(fcc_path, ref_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e59b12-67dd-44ea-a478-b3a577250829",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "toc-autonumbering": true,
  "toc-showmarkdowntxt": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
