{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Jamuna River Cross-section Co-ordinates_automatic",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/heromiya/GEE-LCM/blob/master/Jamuna_River_Cross_section_Co_ordinates_automatic.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K6oqYMKpzGno",
        "outputId": "0329a00b-8ecc-4ba6-c476-59c3aa336f6d"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DT0-B2TUsBJr"
      },
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "import gspread\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "gc = gspread.authorize(GoogleCredentials.get_application_default())\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dqScX1w0zJI5",
        "outputId": "e80c06d6-200c-491a-870b-d6ab49cb009a"
      },
      "source": [
        "!pip install fiona"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting fiona\n",
            "  Downloading Fiona-1.8.20-cp37-cp37m-manylinux1_x86_64.whl (15.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 15.4 MB 35 kB/s \n",
            "\u001b[?25hRequirement already satisfied: click>=4.0 in /usr/local/lib/python3.7/dist-packages (from fiona) (7.1.2)\n",
            "Collecting munch\n",
            "  Downloading munch-2.5.0-py2.py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from fiona) (57.2.0)\n",
            "Collecting cligj>=0.5\n",
            "  Downloading cligj-0.7.2-py3-none-any.whl (7.1 kB)\n",
            "Collecting click-plugins>=1.0\n",
            "  Downloading click_plugins-1.1.1-py2.py3-none-any.whl (7.5 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from fiona) (2021.5.30)\n",
            "Requirement already satisfied: six>=1.7 in /usr/local/lib/python3.7/dist-packages (from fiona) (1.15.0)\n",
            "Requirement already satisfied: attrs>=17 in /usr/local/lib/python3.7/dist-packages (from fiona) (21.2.0)\n",
            "Installing collected packages: munch, cligj, click-plugins, fiona\n",
            "Successfully installed click-plugins-1.1.1 cligj-0.7.2 fiona-1.8.20 munch-2.5.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nduQwnkGzK4y"
      },
      "source": [
        "import fiona\n",
        "import os\n",
        "from shapely.geometry import shape,MultiPolygon,Point,LineString,Polygon\n",
        "from shapely.wkt import loads\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MlTJaoxloe6j"
      },
      "source": [
        "CrossSection Path is crossSection of river at certain place &&\n",
        "predicted is shapefile of river extent predicted by CNN\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x645Mspc0CMF"
      },
      "source": [
        "root_path = 'gdrive/My Drive/Jamuna River/'\n",
        "\n",
        "crossSection_path=root_path+'All CrossSection/'\n",
        "predicted_path=root_path+'Predicted_final/'\n",
        "\n",
        "crossSection_dataset=os.listdir(crossSection_path)\n",
        "predicted_dataset=os.listdir(predicted_path)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-akgxsEX79C1"
      },
      "source": [
        "Sorting Cross Section Line and Predicted shapefile  by Name\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gD3l7LG_oUoO"
      },
      "source": [
        "def sortDriveFile(x):\n",
        "    return(x[0:7])\n",
        "\n",
        "crossSection_dataset=sorted(crossSection_dataset, key = sortDriveFile)  \n",
        "predicted_dataset=sorted(predicted_dataset,key=sortDriveFile) \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OTB3shqmwc4V"
      },
      "source": [
        "Selecting only shapefile and addind to list."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8UadbfXKpFA9"
      },
      "source": [
        "crossSection_dataset_list=[]\n",
        "\n",
        "for shp in crossSection_dataset:\n",
        "  if shp.endswith('.shp'):\n",
        "    crossSection_dataset_list.append(shp)\n",
        "\n",
        "predicted_dataset_list=[]\n",
        "\n",
        "for shp in predicted_dataset:\n",
        "  if shp.endswith('.shp'):\n",
        "    predicted_dataset_list.append(shp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qto5JSG2L5AU",
        "outputId": "824de9a7-8322-42ed-d5c5-f8d6e367d1ce"
      },
      "source": [
        "predicted_dataset_list"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['2007_01_03.shp']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7-m9D22pwcdw"
      },
      "source": [
        "Converting shapefile to geometry of shapely "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t6ry3MNntfar"
      },
      "source": [
        "crossSection_shp=[]\n",
        "for i in range(len(crossSection_dataset_list)):\n",
        "  crossSection=fiona.open(crossSection_path+crossSection_dataset_list[i])\n",
        "  crossSection= next(iter(crossSection))\n",
        "  crossSection_geom = shape(crossSection['geometry']) \n",
        "  crossSection_loads=loads(str(crossSection_geom))\n",
        "  crossSection_shp.append(crossSection_loads)\n",
        "\n",
        "\n",
        "predicted_shp=[]\n",
        "\n",
        "for i in range(len(predicted_dataset_list)):\n",
        "  predicted=fiona.open(predicted_path+predicted_dataset_list[i])\n",
        "  predricted=next(iter(predicted))\n",
        "  predicted_geom = MultiPolygon([shape(predicted['geometry']) for predicted in fiona.open(predicted_path+predicted_dataset_list[i])])\n",
        "  predicted_loads=loads(str(predicted_geom)) \n",
        "  predicted_shp.append(predicted_loads)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "60D5Sa5rakRw",
        "outputId": "b3365d19-11e9-4cad-e5c8-1f621ed69617"
      },
      "source": [
        "for i in range (0, len(predicted_dataset_list)):\n",
        "  predicted_shp[i]=predicted_shp[i].buffer(0)\n",
        "  print(predicted_shp[i].is_valid)\n",
        "  predicted_loads=predicted_shp[i]\n",
        "  name_of_shapefile=(predicted_dataset_list[i].split('.'))[0]\n",
        "  print(name_of_shapefile)\n",
        "  number_of_polygon=len(predicted_loads)\n",
        "  number_of_crossSection=len(crossSection_dataset_list)\n",
        "  number_of_shapefile=len(predicted_shp)\n",
        "  coordinateList=[]\n",
        "  for i in range(number_of_crossSection):\n",
        "    emptyList=[]\n",
        "    coordinateList.append(emptyList)\n",
        "\n",
        "  # for z in range(number_of_shapefile):\n",
        "\n",
        "  for i in range(number_of_polygon):\n",
        "\n",
        "    # eachLine_coordinates=[]\n",
        "    for j in range(number_of_crossSection):\n",
        "      \n",
        "      exterior_intersection = predicted_loads[i].exterior.intersection(crossSection_shp[j])\n",
        "      # print(intersection.geom_type) \n",
        "      if exterior_intersection.is_empty:\n",
        "        pass   \n",
        "        \n",
        "      elif exterior_intersection.geom_type.startswith('Multi')  or exterior_intersection.geom_type == 'GeometryCollection':  \n",
        "\n",
        "        for shp in exterior_intersection:\n",
        "              # print(shp.wkt)\n",
        "              shp=loads(shp.wkt)\n",
        "              if shp.wkt not in coordinateList[j]:\n",
        "                coordinateList[j].append(shp.wkt)\n",
        "                \n",
        "              else:\n",
        "                pass\n",
        "                # print(\"{} already exist\".format(shp.wkt))\n",
        "\n",
        "              \n",
        "\n",
        "      intersection = predicted_loads[i].intersection(crossSection_shp[j])\n",
        "      # print(intersection.geom_type) \n",
        "      if intersection.is_empty:\n",
        "        pass\n",
        "\n",
        "      elif str(intersection).startswith('MULTILINESTRING'): \n",
        "        for shp in intersection:\n",
        "          shp_loads=loads(shp.wkt)\n",
        "          for l in range(40):\n",
        "            \n",
        "            try:\n",
        "              x=shp_loads.xy[0][l]\n",
        "              y=shp_loads.xy[1][l]\n",
        "              # print(x,y)\n",
        "              point=Point(x,y)\n",
        "              # points_xy.append(point.wkt)\n",
        "              if point.wkt not in coordinateList[j]:  \n",
        "                # point_data=point\n",
        "                coordinateList[j].append(point.wkt)\n",
        "              else:\n",
        "                pass\n",
        "                # print(\"{} already exist\".format(point_data.wkt))\n",
        "              \n",
        "              # coordinateList_all.append(point.wkt)\n",
        "            except Exception:\n",
        "              pass\n",
        "              \n",
        "      \n",
        "      elif str(intersection).startswith('LINESTRING'):\n",
        "        shp_load=loads(intersection.wkt)\n",
        "        for k in range(40):\n",
        "          \n",
        "          try:\n",
        "            x=shp_load.xy[0][k]\n",
        "            y=shp_load.xy[1][k]\n",
        "            # print(x,y)\n",
        "            point=Point(x,y)\n",
        "            if point.wkt not in coordinateList[j]:\n",
        "              point_data=point  \n",
        "              coordinateList[j].append(point.wkt)\n",
        "            else:\n",
        "              pass\n",
        "              # print(\"{} already exist\".format(point_data.wkt))\n",
        "            # points_xy.append(point.wkt)\n",
        "            # coordinateList_all.append(point.wkt)\n",
        "          except Exception:\n",
        "            pass\n",
        "  def sortingCoordinates(x):\n",
        "    return(x[8:18])\n",
        "  for i in range(number_of_crossSection):\n",
        "    for j in range(len(coordinateList[i])):\n",
        "      coordinateList[i]=sorted(coordinateList[i], key = sortingCoordinates)\n",
        "  for i in range(34):\n",
        "    m=(i/34)*100\n",
        "    m=round(m)\n",
        "    print(f'{m}% completed')\n",
        "    for point in coordinateList[i]:\n",
        "      def negativeCheck():\n",
        "        xcordn=(loads(point)).x -0.0001\n",
        "        ycordn=(loads(point)).y -0.0001\n",
        "        xy_n =Point(xcordn,ycordn)\n",
        "        return xy_n.within(predicted_loads)\n",
        "\n",
        "      def positiveCheck():\n",
        "        xcordp=(loads(point)).x +0.0001\n",
        "        ycordp=(loads(point)).y +0.0001\n",
        "        xy_p =Point(xcordp,ycordp)\n",
        "        return xy_p.within(predicted_loads)\n",
        "\n",
        "      if negativeCheck()==True and positiveCheck()==True:\n",
        "        coordinateList[i].remove(point)\n",
        "      else:\n",
        "        pass\n",
        "  \n",
        "  import gspread\n",
        "  from oauth2client.client import GoogleCredentials\n",
        "  gc = gspread.authorize(GoogleCredentials.get_application_default())\n",
        "  # create a new spreadsheet with name\n",
        "  sh = gc.create(name_of_shapefile)\n",
        "  # Open our new sheet and add some data.\n",
        "  wks = gc.open(name_of_shapefile).sheet1\n",
        "  name_cell_lists = wks.range('A2:A35')\n",
        "  row_head_lists=wks.range(\"B1:AZ1\")\n",
        "\n",
        "  for i in range(30):\n",
        "    k=i*2\n",
        "    l=k+1\n",
        "    try:\n",
        "      row_head_lists[k].value=\"X{}\".format(i+1)\n",
        "      row_head_lists[l].value=\"Y{}\".format(i+1)\n",
        "    except Exception:\n",
        "      pass\n",
        "\n",
        "\n",
        "  for i in range(len(crossSection_dataset_list)):\n",
        "    x=(crossSection_dataset_list[i].split('.shp'))[0]\n",
        "    name_cell_lists[i].value=x\n",
        "\n",
        "  wks.update_cells(name_cell_lists)\n",
        "  wks.update_cells(row_head_lists)\n",
        "  \n",
        "  cell_list_coordinate=[]\n",
        "  for i in range(len(coordinateList)):\n",
        "    cell_list_coordinate.append('B{}:AE{}'.format(i+2,i+2))\n",
        "\n",
        "\n",
        "  for p in range(len(coordinateList)):\n",
        "    cells=None\n",
        "    cells=wks.range(cell_list_coordinate[p])\n",
        "    for i in range(len(coordinateList[p])):\n",
        "      k=i*2\n",
        "      l=k+1  \n",
        "      try:\n",
        "        cells[k].value=str(loads(coordinateList[p][i]).x)\n",
        "        cells[l].value=str(loads(coordinateList[p][i]).y)\n",
        "      except Exception:\n",
        "        pass\n",
        "    wks.update_cells(cells)\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n",
            "2007_01_03\n",
            "0% completed\n",
            "3% completed\n",
            "6% completed\n",
            "9% completed\n",
            "12% completed\n",
            "15% completed\n",
            "18% completed\n",
            "21% completed\n",
            "24% completed\n",
            "26% completed\n",
            "29% completed\n",
            "32% completed\n",
            "35% completed\n",
            "38% completed\n",
            "41% completed\n",
            "44% completed\n",
            "47% completed\n",
            "50% completed\n",
            "53% completed\n",
            "56% completed\n",
            "59% completed\n",
            "62% completed\n",
            "65% completed\n",
            "68% completed\n",
            "71% completed\n",
            "74% completed\n",
            "76% completed\n",
            "79% completed\n",
            "82% completed\n",
            "85% completed\n",
            "88% completed\n",
            "91% completed\n",
            "94% completed\n",
            "97% completed\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}